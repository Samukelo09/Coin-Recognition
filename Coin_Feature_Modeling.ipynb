{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMe+d4MHMfJTFc0/ecRkb3f"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["# **Morphology**"],"metadata":{"id":"7O3Vcjgh9WOu"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":489},"id":"S4aGTds79HQP","executionInfo":{"status":"ok","timestamp":1749212731023,"user_tz":-120,"elapsed":73126,"user":{"displayName":"Wandile Ngobese","userId":"09332245198736117830"}},"outputId":"9637e319-ffeb-4465-de55-a6b9945f2c69"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-aa51e5eb-416d-4640-96d2-c9f95bde2b67\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-aa51e5eb-416d-4640-96d2-c9f95bde2b67\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving coin_features_morphology.csv to coin_features_morphology.csv\n","âœ… Accuracy: 0.5034891835310538\n","\n","ğŸ§¾ Classification Report:\n","               precision    recall  f1-score   support\n","\n","    10c_back       0.65      0.78      0.71       200\n","   10c_front       0.53      0.47      0.49       200\n","    20c_back       0.54      0.41      0.47       200\n","   20c_front       0.49      0.36      0.42       200\n","    50c_back       0.46      0.51      0.48       200\n","   50c_front       0.52      0.51      0.51       200\n","     5c_back       0.51      0.53      0.52       200\n","    5c_front       0.50      0.35      0.41       200\n","     R1_back       0.44      0.72      0.54       200\n","    R1_front       0.54      0.38      0.44       200\n","     R2_back       0.53      0.45      0.48       200\n","    R2_front       0.48      0.54      0.51       200\n","     R5_back       0.56      0.34      0.43       200\n","    R5_front       0.44      0.65      0.53       266\n","\n","    accuracy                           0.50      2866\n","   macro avg       0.51      0.50      0.50      2866\n","weighted avg       0.51      0.50      0.50      2866\n","\n"]}],"source":["# Step 1: Upload CSV\n","from google.colab import files\n","uploaded = files.upload()\n","\n","# Step 2: Load DataFrame\n","import pandas as pd\n","import numpy as np\n","\n","filename = list(uploaded.keys())[0]\n","df = pd.read_csv(filename)\n","\n","# Step 3: Oversampling with noise\n","from collections import Counter\n","\n","def oversample_with_noise(X, y, target_count=1000, noise_level=0.02):\n","    X_new, y_new = list(X), list(y)\n","    class_counts = Counter(y)\n","\n","    for label in np.unique(y):\n","        current_count = class_counts[label]\n","        if current_count >= target_count:\n","            continue\n","\n","        class_indices = np.where(y == label)[0]\n","        needed = target_count - current_count\n","\n","        for _ in range(needed):\n","            idx = np.random.choice(class_indices)\n","            noisy_sample = X[idx] + np.random.normal(0, noise_level, X.shape[1])\n","            X_new.append(noisy_sample)\n","            y_new.append(label)\n","\n","    return np.array(X_new), np.array(y_new)\n","\n","# Step 4: Prepare features and labels\n","X = df.drop('label', axis=1).values\n","y = df['label'].values\n","\n","# Step 5: Oversample\n","X_bal, y_bal = oversample_with_noise(X, y, target_count=1000, noise_level=0.02)\n","\n","# Step 6: Train/Test split\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X_bal, y_bal, test_size=0.2, stratify=y_bal, random_state=42)\n","\n","# Step 7: Normalize\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# Step 8: Train Random Forest model\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report\n","\n","model = RandomForestClassifier(n_estimators=100, random_state=42)\n","model.fit(X_train, y_train)\n","\n","# Step 9: Evaluate\n","print(\"âœ… Accuracy:\", model.score(X_test, y_test))\n","print(\"\\nğŸ§¾ Classification Report:\\n\", classification_report(y_test, model.predict(X_test)))\n","\n","\n"]},{"cell_type":"code","source":["# Step 10: Convert to TensorFlow (via Keras Functional API)\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","\n","# One-hot encode the labels\n","from sklearn.preprocessing import LabelEncoder\n","from tensorflow.keras.utils import to_categorical\n","\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y_bal)\n","num_classes = len(label_encoder.classes_)\n","\n","# Train/test split again with encoded labels\n","X_train_nn, X_test_nn, y_train_nn, y_test_nn = train_test_split(X_bal, y_encoded, test_size=0.2, stratify=y_encoded, random_state=42)\n","\n","# Normalize\n","X_train_nn = scaler.fit_transform(X_train_nn)\n","X_test_nn = scaler.transform(X_test_nn)\n","\n","# Convert labels to categorical\n","y_train_nn_cat = to_categorical(y_train_nn, num_classes)\n","y_test_nn_cat = to_categorical(y_test_nn, num_classes)\n","\n","# Define a small neural network\n","model_nn = keras.Sequential([\n","    layers.Input(shape=(X_train_nn.shape[1],)),\n","    layers.Dense(128, activation='relu'),\n","    layers.Dense(64, activation='relu'),\n","    layers.Dense(num_classes, activation='softmax')\n","])\n","\n","model_nn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","model_nn.fit(X_train_nn, y_train_nn_cat, epochs=20, batch_size=32, validation_data=(X_test_nn, y_test_nn_cat))\n","\n","# Step 11: Convert to TFLite\n","converter = tf.lite.TFLiteConverter.from_keras_model(model_nn)\n","tflite_model = converter.convert()\n","\n","# Save the TFLite model\n","with open('coin_classifier_model.tflite', 'wb') as f:\n","    f.write(tflite_model)\n","\n","# Step 12: Download the TFLite model\n","files.download('coin_classifier_model.tflite')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":937},"id":"rs5d9WtvMtcl","executionInfo":{"status":"ok","timestamp":1749212789330,"user_tz":-120,"elapsed":34966,"user":{"displayName":"Wandile Ngobese","userId":"09332245198736117830"}},"outputId":"fb687b24-af74-49b8-bf79-1460f0cc1601"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","\u001b[1m359/359\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.1440 - loss: 2.5683 - val_accuracy: 0.1950 - val_loss: 2.3792\n","Epoch 2/20\n","\u001b[1m359/359\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2327 - loss: 2.2964 - val_accuracy: 0.2303 - val_loss: 2.2831\n","Epoch 3/20\n","\u001b[1m359/359\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2646 - loss: 2.1782 - val_accuracy: 0.2446 - val_loss: 2.2255\n","Epoch 4/20\n","\u001b[1m359/359\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.2921 - loss: 2.0683 - val_accuracy: 0.2579 - val_loss: 2.1666\n","Epoch 5/20\n","\u001b[1m359/359\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3202 - loss: 1.9996 - val_accuracy: 0.2851 - val_loss: 2.1161\n","Epoch 6/20\n","\u001b[1m359/359\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3243 - loss: 1.9406 - val_accuracy: 0.2847 - val_loss: 2.0871\n","Epoch 7/20\n","\u001b[1m359/359\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3565 - loss: 1.8777 - val_accuracy: 0.2917 - val_loss: 2.0795\n","Epoch 8/20\n","\u001b[1m359/359\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3607 - loss: 1.8468 - val_accuracy: 0.2945 - val_loss: 2.0753\n","Epoch 9/20\n","\u001b[1m359/359\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.3827 - loss: 1.7967 - val_accuracy: 0.2987 - val_loss: 2.0529\n","Epoch 10/20\n","\u001b[1m359/359\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.3930 - loss: 1.7391 - val_accuracy: 0.2997 - val_loss: 2.0527\n","Epoch 11/20\n","\u001b[1m359/359\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4127 - loss: 1.7044 - val_accuracy: 0.3053 - val_loss: 2.0296\n","Epoch 12/20\n","\u001b[1m359/359\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4216 - loss: 1.6710 - val_accuracy: 0.3151 - val_loss: 2.0473\n","Epoch 13/20\n","\u001b[1m359/359\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4318 - loss: 1.6516 - val_accuracy: 0.3112 - val_loss: 2.0336\n","Epoch 14/20\n","\u001b[1m359/359\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4523 - loss: 1.6077 - val_accuracy: 0.3102 - val_loss: 2.0430\n","Epoch 15/20\n","\u001b[1m359/359\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4490 - loss: 1.5942 - val_accuracy: 0.3234 - val_loss: 2.0362\n","Epoch 16/20\n","\u001b[1m359/359\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4658 - loss: 1.5586 - val_accuracy: 0.3252 - val_loss: 2.0344\n","Epoch 17/20\n","\u001b[1m359/359\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4726 - loss: 1.5263 - val_accuracy: 0.3262 - val_loss: 2.0536\n","Epoch 18/20\n","\u001b[1m359/359\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4738 - loss: 1.5188 - val_accuracy: 0.3221 - val_loss: 2.0804\n","Epoch 19/20\n","\u001b[1m359/359\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.4846 - loss: 1.4851 - val_accuracy: 0.3304 - val_loss: 2.0649\n","Epoch 20/20\n","\u001b[1m359/359\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.4918 - loss: 1.4750 - val_accuracy: 0.3168 - val_loss: 2.0904\n","Saved artifact at '/tmp/tmpczcggara'. The following endpoints are available:\n","\n","* Endpoint 'serve'\n","  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 52), dtype=tf.float32, name='keras_tensor')\n","Output Type:\n","  TensorSpec(shape=(None, 14), dtype=tf.float32, name=None)\n","Captures:\n","  137672533268560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  137672533272592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  137672533274128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  137672533269136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  137672533274320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n","  137672533269904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["download(\"download_11c61a92-b48d-45d1-9252-4a477bd3acfc\", \"coin_classifier_model.tflite\", 65904)"]},"metadata":{}}]},{"cell_type":"markdown","source":["**SMOTE**"],"metadata":{"id":"x3oXBVOXNr0P"}},{"cell_type":"code","source":["# Step 1: Upload CSV\n","from google.colab import files\n","uploaded = files.upload()\n","\n","# Step 2: Load CSV\n","import pandas as pd\n","\n","filename = list(uploaded.keys())[0]\n","df = pd.read_csv(filename)\n","\n","# Step 3: Prepare features and labels\n","X = df.drop('label', axis=1).values\n","y = df['label'].values\n","\n","# Step 4: Apply SMOTE\n","from imblearn.over_sampling import SMOTE\n","from sklearn.preprocessing import LabelEncoder\n","\n","label_encoder = LabelEncoder()\n","y_encoded = label_encoder.fit_transform(y)\n","\n","smote = SMOTE(random_state=42)\n","X_resampled, y_resampled = smote.fit_resample(X, y_encoded)\n","\n","# Step 5: Train/Test Split\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X_resampled, y_resampled, test_size=0.2, stratify=y_resampled, random_state=42\n",")\n","\n","# Step 6: Normalize\n","from sklearn.preprocessing import StandardScaler\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# Step 7: Train Random Forest\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report\n","\n","rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n","rf_model.fit(X_train, y_train)\n","\n","print(\"âœ… Accuracy:\", rf_model.score(X_test, y_test))\n","print(\"\\nğŸ§¾ Classification Report:\\n\", classification_report(y_test, rf_model.predict(X_test)))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":489},"id":"D-4TSLaYNrNw","executionInfo":{"status":"ok","timestamp":1749213024402,"user_tz":-120,"elapsed":69414,"user":{"displayName":"Wandile Ngobese","userId":"09332245198736117830"}},"outputId":"8f283942-c5b8-4067-f553-5afdb298922f"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-56d25c83-9a80-43aa-a9cd-d35249996b06\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-56d25c83-9a80-43aa-a9cd-d35249996b06\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving coin_features_morphology.csv to coin_features_morphology (1).csv\n","âœ… Accuracy: 0.764183920408712\n","\n","ğŸ§¾ Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.90      0.96      0.93       265\n","           1       0.79      0.79      0.79       266\n","           2       0.80      0.86      0.83       266\n","           3       0.71      0.72      0.71       266\n","           4       0.80      0.80      0.80       266\n","           5       0.74      0.72      0.73       265\n","           6       0.75      0.82      0.78       266\n","           7       0.75      0.70      0.73       266\n","           8       0.78      0.96      0.86       266\n","           9       0.78      0.75      0.76       265\n","          10       0.80      0.79      0.80       266\n","          11       0.71      0.68      0.69       265\n","          12       0.73      0.73      0.73       265\n","          13       0.60      0.43      0.50       266\n","\n","    accuracy                           0.76      3719\n","   macro avg       0.76      0.76      0.76      3719\n","weighted avg       0.76      0.76      0.76      3719\n","\n"]}]}]}